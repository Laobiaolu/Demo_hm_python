# 安装一个requests

#安装中有些文件可能拉取不到可以使用将网络模式改为host，解决了问题
#docker build --network=host -t centeradmin . --no-cache

FROM python:3.6

#RUN set -eux && sed -i 's/dl-cdn.alpinelinux.org/mirrors.ustc.edu.cn/g' /etc/apk/repositories

RUN pip install --upgrade pip

RUN sed -i 's/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g' /etc/apk/repositories

#RUN /usr/local/bin/python -m pip install --upgrade pip

RUN apk add --no-cache --virtual build-dependencies \
python3-dev \
libffi-dev \
openssl-dev \
gcc \
libc-dev \
make

#安装gcc编译环境
RUN apk update \
    && apk add --no-cache gcc musl-dev \
    && apk update \
    && apk add --no-cache gcc \
    && apk add --no-cache g++ \
    && apk add --no-cache make \
    && apk add --no-cache libffi-dev \
    && apk add --no-cache openssl-dev

#下列模块的安装需要gcc编译环境
RUN pip install twisted &&\
    pip install gevent

# 安装支持http/HTTPS协议客户端请求的库
RUN pip install wheel && \
    pip install requests && \
    pip install aiohttp && \
    pip install tornado && \
    pip install selenium && \
    pip install appium-python-client



#安装 scrapy
#Ubuntu下依赖：libxml2-dev libxslt-dev zliblg-dev libffi-dev libssl-dev
RUN apk add --no-cache libxml2-dev libxslt-dev zlib-dev libffi-dev openssl-dev &&\
    pip install scrapy

##安装pyspider
##Ubuntu下依赖：
RUN apk add --no-cache curl-dev openssl-dev libxml2-dev libxslt-dev zlib-dev &&\
    pip install pyspider